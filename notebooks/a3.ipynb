{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, precision_score, accuracy_score, homogeneity_completeness_v_measure, homogeneity_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import feature_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 \n",
    "For this problem you will experiment with linear regression models to make predictions with numerical data. You will\n",
    "also explore more systematic methods for feature selection and for optimizing model parameters (model selection).\n",
    "The data set you will use is a subset of the \"Communities and Crime\" data set that combines information from the\n",
    "1990 census data as well as FBI crime data from 1995. Please read the full description of the data, including the\n",
    "description and statistics on different variables. The target attribute for regression purposes is\n",
    "\"ViolentCrimesPerPop\". The two identifier attributes \"state\" and \"community name\" should be excluded for the\n",
    "regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "url = r'https://raw.githubusercontent.com/PixarJunkie/dsc478-programming-ml-applications/master/data/communities-data/communities.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1a \n",
    "Load and preprocess the data using Pandas or Numpy and, if necessary, preprocessing functions from\n",
    "scikit-learn. The provided data is already normalized (see description), so there is no need for\n",
    "additional normalization. Compute and display basic statistics (mean, standard deviation, min, max, etc.)\n",
    "for each of the variables in the data set. Separate the target attribute for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove ?\n",
    "df = df[df.OtherPerCap != '?']\n",
    "#Seperate target variable and drop state/communityname\n",
    "target = df.ViolentCrimesPerPop\n",
    "df.drop(columns = ['ViolentCrimesPerPop', 'state', 'communityname'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.463437</td>\n",
       "      <td>0.179227</td>\n",
       "      <td>0.753984</td>\n",
       "      <td>0.153753</td>\n",
       "      <td>0.144089</td>\n",
       "      <td>0.424210</td>\n",
       "      <td>0.493914</td>\n",
       "      <td>0.336297</td>\n",
       "      <td>0.423086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029453</td>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.215655</td>\n",
       "      <td>0.608776</td>\n",
       "      <td>0.534967</td>\n",
       "      <td>0.626322</td>\n",
       "      <td>0.651470</td>\n",
       "      <td>0.065243</td>\n",
       "      <td>0.232910</td>\n",
       "      <td>0.161741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.126935</td>\n",
       "      <td>0.163747</td>\n",
       "      <td>0.252870</td>\n",
       "      <td>0.243807</td>\n",
       "      <td>0.208905</td>\n",
       "      <td>0.232531</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>0.143584</td>\n",
       "      <td>0.166540</td>\n",
       "      <td>0.179196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102630</td>\n",
       "      <td>0.100424</td>\n",
       "      <td>0.231146</td>\n",
       "      <td>0.204314</td>\n",
       "      <td>0.181360</td>\n",
       "      <td>0.200520</td>\n",
       "      <td>0.198253</td>\n",
       "      <td>0.109485</td>\n",
       "      <td>0.203127</td>\n",
       "      <td>0.229099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "count  1993.000000    1993.000000   1993.000000   1993.000000   1993.000000   \n",
       "mean      0.057612       0.463437      0.179227      0.753984      0.153753   \n",
       "std       0.126935       0.163747      0.252870      0.243807      0.208905   \n",
       "min       0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%       0.010000       0.350000      0.020000      0.630000      0.040000   \n",
       "50%       0.020000       0.440000      0.060000      0.850000      0.070000   \n",
       "75%       0.050000       0.540000      0.230000      0.940000      0.170000   \n",
       "max       1.000000       1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       racePctHisp  agePct12t21  agePct12t29  agePct16t24   agePct65up  \\\n",
       "count  1993.000000  1993.000000  1993.000000  1993.000000  1993.000000   \n",
       "mean      0.144089     0.424210     0.493914     0.336297     0.423086   \n",
       "std       0.232531     0.155234     0.143584     0.166540     0.179196   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.010000     0.340000     0.410000     0.250000     0.300000   \n",
       "50%       0.040000     0.400000     0.480000     0.290000     0.420000   \n",
       "75%       0.160000     0.470000     0.540000     0.360000     0.530000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            ...        NumInShelters    NumStreet  PctForeignBorn  \\\n",
       "count       ...          1993.000000  1993.000000     1993.000000   \n",
       "mean        ...             0.029453     0.022790        0.215655   \n",
       "std         ...             0.102630     0.100424        0.231146   \n",
       "min         ...             0.000000     0.000000        0.000000   \n",
       "25%         ...             0.000000     0.000000        0.060000   \n",
       "50%         ...             0.000000     0.000000        0.130000   \n",
       "75%         ...             0.010000     0.000000        0.280000   \n",
       "max         ...             1.000000     1.000000        1.000000   \n",
       "\n",
       "       PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  \\\n",
       "count       1993.000000     1993.000000    1993.000000     1993.000000   \n",
       "mean           0.608776        0.534967       0.626322        0.651470   \n",
       "std            0.204314        0.181360       0.200520        0.198253   \n",
       "min            0.000000        0.000000       0.000000        0.000000   \n",
       "25%            0.470000        0.420000       0.520000        0.560000   \n",
       "50%            0.630000        0.540000       0.670000        0.700000   \n",
       "75%            0.770000        0.660000       0.770000        0.790000   \n",
       "max            1.000000        1.000000       1.000000        1.000000   \n",
       "\n",
       "          LandArea      PopDens  PctUsePubTrans  \n",
       "count  1993.000000  1993.000000     1993.000000  \n",
       "mean      0.065243     0.232910        0.161741  \n",
       "std       0.109485     0.203127        0.229099  \n",
       "min       0.000000     0.000000        0.000000  \n",
       "25%       0.020000     0.100000        0.020000  \n",
       "50%       0.040000     0.170000        0.070000  \n",
       "75%       0.070000     0.280000        0.190000  \n",
       "max       1.000000     1.000000        1.000000  \n",
       "\n",
       "[8 rows x 96 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic stats\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1395, 97)\n",
      "X_test shape: (598, 97)\n",
      "y_train shape: (1395,)\n",
      "y_test shape: (598,)\n"
     ]
    }
   ],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size = 0.3, random_state = 23)\n",
    "print('X_train shape: ' + str(X_train.shape))\n",
    "print('X_test shape: ' + str(X_test.shape))\n",
    "print('y_train shape: ' + str(y_train.shape))\n",
    "print('y_test shape: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1b \n",
    "Perform standard linear regression on data using the implementation for Ch. 8 of MLA. Compute the\n",
    "RMSE value on the full training data. Also, plot the correlation between the predicted and actual values of\n",
    "the target attribute. Display the obtained regression coefficients (weights). Finally, perform 10-fold crossvalidation and compare the cross-validation RMSE to the training RMSE (for cross validation, you should\n",
    "use the KFoldmodule from sklearn.cross_validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE = 0.12706984575174946\n",
      "Regression coeff: [ 0.18180384 -0.02456446  0.19336785 -0.0692231   0.02402757  0.10533693\n",
      "  0.10651976 -0.28684654 -0.00450859  0.15568013 -0.34153117  0.05689896\n",
      " -0.31278512 -0.17418009  0.05200266 -0.20547294 -0.05745159  0.0418954\n",
      " -0.06378795  0.41571875  0.16334943 -0.35312853 -0.0255256  -0.04713248\n",
      "  0.02572615  0.05822205  0.02050493  0.16697108 -0.18455236 -0.04589169\n",
      "  0.04642044  0.05984499 -0.00723915  0.16686814 -0.01012395  0.00999885\n",
      "  0.70361587  0.16266403  0.5734757  -1.13766631 -0.41501933 -0.01946235\n",
      " -0.19851608 -0.0338486  -0.0116426   0.05942284 -0.16889839 -0.20970299\n",
      "  0.17295796 -0.1320901   0.02803919  0.05267064 -0.12199557  0.04132845\n",
      "  0.01107641 -0.33486353  0.45899263 -0.11096538  0.0702354  -0.08814446\n",
      "  0.23000182 -0.30240472  0.55610593  0.30003273 -0.31591065 -1.2280806\n",
      "  0.15916502  0.05334984  0.02512211  0.22149232 -0.02516277  1.15062278\n",
      "  0.02449627 -0.06814524 -0.05416636  0.01070542 -0.02373715 -0.38539679\n",
      "  0.39428161 -0.11960818 -0.26154955  0.09102648 -0.02396149  0.28271551\n",
      " -0.00583818 -0.0416039  -0.03452352  0.1641573   0.12480197  0.08307837\n",
      " -0.03258087 -0.08831873  0.04827983  0.04442258  0.00529837 -0.01373551\n",
      " -0.03441289]\n"
     ]
    }
   ],
   "source": [
    "#Base model\n",
    "reg = LinearRegression()\n",
    "#Fit model\n",
    "model = reg.fit(X_train, y_train)\n",
    "train_preds = model.predict(X_train)\n",
    "#Training rmse\n",
    "print('Training RMSE = ' + str(np.sqrt(mean_squared_error(train_preds, y_train))))\n",
    "print('Regression coeff: ' + str(model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2a3a3dcab38>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training preds vs. actual\n",
    "plt.scatter(train_preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv scores: [0.66115654 0.67181177 0.59008449 0.6258997  0.63665183 0.61778658\n",
      " 0.71202608 0.55823714 0.54092493 0.6308973 ]\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation\n",
    "cv_10f = cross_val_score(reg, X_train, y_train, cv = 10)\n",
    "print('cv scores: ' + str(cv_10f))\n",
    "#Cross-validation preds\n",
    "cv_10f_preds = cross_val_predict(reg, X_train, y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kf_MSE: 0.13883607250349875\n",
      "cv_mse RMSE: 0.13932669369452322\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation RMSE through mean_squared_error module\n",
    "kf = KFold(len(X_train), n_folds = 10)\n",
    "x_val = 0\n",
    "for train_ind, test_ind in kf:\n",
    "    reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    err = pred - y_test\n",
    "    x_val += np.sqrt(np.dot(err, err) / len(X_test))\n",
    "       \n",
    "cv_10f_kf = x_val / 10\n",
    "print('kf_MSE: ' + str(cv_10f_kf))\n",
    "\n",
    "#Cross-validation RMSE through mean_squared_error module\n",
    "print('cv_mse RMSE: ' + str(np.sqrt(mean_squared_error(cv_10f_preds, y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1c \n",
    "Feature Selection: use the scikit-learn regression model from sklearn.linear_model with a subset\n",
    "of features to perform linear regression. For feature selection, write a script or function that takes as input\n",
    "the training data, target variable; the model; and any other parameters you find necessary, and returns the\n",
    "optimal percentage of the most informative features to use. Your approach should use k-fold crossvalidation on the training data (you can use k=5). You can\n",
    "use feature_selection.SelectPercentile to find the most informative variables. Show the list of\n",
    "most informative variables and their weights Note: since this is regression not classification, you should\n",
    "use feature_selection.f_regression as scoring function rather than chi2). Next, plot the model's mean\n",
    "absolute error values on cross-validation relative to the percentage of selected features (See scikitlearn's metrics.mean_absolute_error). In order to use cross_validation.cross_val_score with\n",
    "regression you'll need to pass to it scoring='mean_absolute_error' as a parameter. Review scikitlearn documentation for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feats(train_data, train_labels, model_):\n",
    "    opt_feats = []\n",
    "    perc = list(range(1, 100, 1))\n",
    "    for i in range(1, 100, 1):\n",
    "        fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile = i)\n",
    "        train_fs = fs.fit_transform(train_data, train_labels)\n",
    "        scores = abs(cross_val_score(model_, train_fs, train_labels, scoring = 'mean_absolute_error', cv = 5))\n",
    "        opt_feats = np.append(opt_feats, scores.mean())\n",
    "    opt_perc = np.where(opt_feats == opt_feats.max())[0]\n",
    "    opt_num = int(perc[opt_perc[0]] * len(train_data.columns) / 100)\n",
    "    return opt_perc[0], opt_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get perc and num for features\n",
    "best = best_feats(X_train, y_train, LinearRegression())\n",
    "\n",
    "#Fit opt_perc from best \n",
    "fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile = best[0])\n",
    "train_fs = fs.fit(X_train, y_train)\n",
    "scores = abs(cross_val_score(LinearRegression(), X_train, y_train, scoring = 'mean_absolute_error', cv = 5))\n",
    "\n",
    "#Create new df with feature indexes\n",
    "cols = train_fs.get_support()\n",
    "col_names = list(X_train.columns[cols])\n",
    "features_df_train = X_train[col_names]\n",
    "features_df_test = X_test[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kf_MSE: 0.1414994701879717\n",
      "cv_mse RMSE: 0.13932669369452322\n"
     ]
    }
   ],
   "source": [
    "#RSME with subset df on top featues\n",
    "#Cross-validation RMSE through mean_squared_error module\n",
    "kf = KFold(len(features_df_train), n_folds = 10)\n",
    "x_val = 0\n",
    "for train_ind, test_ind in kf:\n",
    "    reg.fit(features_df_train, y_train)\n",
    "    pred = reg.predict(features_df_test)\n",
    "    err = pred - y_test\n",
    "    x_val += np.sqrt(np.dot(err, err) / len(features_df_test))\n",
    "       \n",
    "cv_10f_kf = x_val / 10\n",
    "print('kf_MSE: ' + str(cv_10f_kf))\n",
    "\n",
    "#Cross-validation RMSE through mean_squared_error module\n",
    "print('cv_mse RMSE: ' + str(np.sqrt(mean_squared_error(cv_10f_preds, y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1d \n",
    "Next, perform Ridge Regression and Lasso Regression using the modules\n",
    "from sklearn.linear_model. In each case, perform systematic model selection to identify the\n",
    "optimal alpha parameter. First, create a 20%-80% randomized split of the data. Set aside the test portion;\n",
    "the model selection process should be performed using the 80% training data partition. You should create a\n",
    "function that takes as input the data and target variable; the parameter to vary and a list of its values; the\n",
    "model to be trained; and any other relevant input needed to determine the optimal value for the specified\n",
    "parameter. The model selection process should perform k-fold cross validation (k should be a parameter, \n",
    "but you can select k=5 for this problem). You should also plot the error values on the training and crossvalidation splits across the specified values of the alphaparameter. Finally, using the best alpha value,\n",
    "run the model on the set-aside test data. Discuss your observation and conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression (using the same train/test data from the prior parts)\n",
    "def ridge_lasso(data, label, model_, param, param_range):\n",
    "    #Ridge\n",
    "    if model_ == 1:\n",
    "        results = []\n",
    "        #Test params in param_range\n",
    "        for num in param_range:\n",
    "            #Base model\n",
    "            rr = Ridge(alpha = num)\n",
    "            #Cv with scores\n",
    "            rr_cv_scores = abs(cross_val_score(rr, data, label, scoring = 'mean_absolute_error', cv = 5))\n",
    "            #Add to results\n",
    "            if len(results) == 0:\n",
    "                results.extend([num, rr_cv_scores.max()])\n",
    "            #Replace results with better cv score\n",
    "            elif rr_cv_scores.max() > results[1]:\n",
    "                results = [num, rr_cv_scores.max()]\n",
    "        best_rr = Ridge(alpha = results[0])\n",
    "        best_model = best_rr.fit(data, label)\n",
    "        print(results)\n",
    "    \n",
    "    #Lasso\n",
    "    if model_ == 0:\n",
    "        results = []\n",
    "        #Test params in param_range\n",
    "        for num in param_range:\n",
    "            #Base model\n",
    "            lm = Lasso(alpha = num)\n",
    "            #Cv with scores\n",
    "            lm_cv_scores = abs(cross_val_score(lm, data, label, scoring = 'mean_absolute_error', cv = 5))\n",
    "            #Add to results\n",
    "            if len(results) == 0:\n",
    "                results.extend([num, lm_cv_scores.max()])\n",
    "            #Replace results with better cv score\n",
    "            elif lm_cv_scores.max() > results[1]:\n",
    "                results = [num, lm_cv_scores.max()]\n",
    "        best_lm = Lasso(alpha = results[0])\n",
    "        best_model = best_lm.fit(data, label)\n",
    "        print(results)\n",
    "    #Return model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.1036798487480546]\n",
      "RMSE: 0.13753920468232295\n",
      " \n",
      "[0.1, 0.18164229005279992]\n",
      "RMSE: 0.24213965360863646\n"
     ]
    }
   ],
   "source": [
    "#Ridge model and RMSE\n",
    "model = ridge_lasso(X_train, y_train, 1, 'aplha', list(np.linspace(0.1, 1, 10)))\n",
    "preds = model.predict(X_test)\n",
    "print('RMSE: ' + str(np.sqrt(mean_squared_error(preds, y_test))))\n",
    "print(' ')\n",
    "\n",
    "#Lasso model and RMSE\n",
    "model = ridge_lasso(X_train, y_train, 0, 'aplha', list(np.linspace(0.1, 1, 20)))\n",
    "preds = model.predict(X_test)\n",
    "print('RMSE: ' + str(np.sqrt(mean_squared_error(preds, y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion \n",
    "From looking at the RMSE between the two models it appears that Lasso performs better in this case. I would also look into the accuracy, percision, and AUC curves of both models before making the final decision. I was surprised to see that in both cases the best alpha was the one that had the best cv score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1e \n",
    "Next, perform regression using Stochastic Gradient Descent for regression. For this part, you should use\n",
    "the SGDRegessor module from sklearn.linear_model. Again, start by a creating randomized 80%-\n",
    "20% train-test split. SGDRegessor requires that features be standardized (with 0 mean and scaled by\n",
    "standard deviation). Prior to fiting the model, perform the scaling\n",
    "using StandardScaler from sklearn.preprocessing. For this problem, perform a grid search\n",
    "(using GridSearchCV from sklearn.grid_search) Your grid search should compare combinations of\n",
    "two penalty parameters ('l2', 'l1') and different values of alpha (alpha could vary from 0.0001 which is the\n",
    "default to relatively large values, say 10). Using the best parameters, apply the model to the set-aside test\n",
    "data. Finally, perform model selection (similar to part d, above) to find the best \"l1_ratio\" parameter using\n",
    "SGDRegressor with the \"elasticnet\" penalty parameter. Note: \"l1_ratio\" is The Elastic Net mixing\n",
    "parameter, with 0 <= l1_ratio <= 1; l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1 penalty; defaults\n",
    "to 0.15. Using the best mixing ratio, apply the Elastic Net model to the set-aside test data. Provide a\n",
    "summary of your findings from the above experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'penalty': 'l1'} 0.6202439592221028\n",
      "RMSE 0.019189902116753508\n",
      " \n",
      "{'alpha': 0.0001, 'l1_ratio': 0.7157894736842105, 'penalty': 'l1'} 0.6217674459250742\n",
      "RMSE 0.02162733245999105\n"
     ]
    }
   ],
   "source": [
    "#Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_fit = scaler.fit_transform(X_train)\n",
    "X_test_fit = scaler.fit_transform(X_test)\n",
    "\n",
    "#params for gridsearch\n",
    "params = {'penalty': ['l2', 'l1'], 'alpha': [0.0001, 0.1, 1, 4, 6, 9]}\n",
    "#Base SGD model\n",
    "sgd = SGDRegressor()\n",
    "#Gridsearch model\n",
    "gs = GridSearchCV(sgd, param_grid = params)\n",
    "#Fit gs to X_train_fit\n",
    "gs_model = gs.fit(X_train_fit, y_train)\n",
    "#Predict X_test_fit gs to test data\n",
    "gs_preds = gs_model.predict(X_test_fit)\n",
    "print(gs.best_params_, gs.best_score_)\n",
    "print('RMSE ' + str(mean_squared_error(gs_preds, y_test)))\n",
    "\n",
    "##params for gridsearch\n",
    "params = {'penalty': ['l1'], 'alpha': [0.0001, 0.1, 1, 4, 6, 9], 'l1_ratio': list(np.linspace(0.1, 1, 20))}\n",
    "sgd = SGDRegressor()\n",
    "#Gridsearch model\n",
    "gs = GridSearchCV(sgd, param_grid = params)\n",
    "#Fit gs to X_train_fit\n",
    "gs_model = gs.fit(X_train_fit, y_train)\n",
    "#Predict X_test_fit gs to test data\n",
    "gs_preds = gs_model.predict(X_test_fit)\n",
    "print(' ')\n",
    "print(gs.best_params_, gs.best_score_)\n",
    "print('RMSE ' + str(mean_squared_error(gs_preds, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion \n",
    "There doesn't appear to be much of a difference when varying the 'l1_ratio' and leaving it at the default 0.15. In fact, the best scores between the two best scores was trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 \n",
    "For this problem you will use a different subset of the 20 Newsgroup data set that you used in Assignment 2 (see\n",
    "the description of the full dataset). The subset for this assignment includes 2,500 documents (newsgroup posts),\n",
    "each belonging to one of 5 categories windows (0), crypt (1), christian (2), hockey (3), forsale (4). The\n",
    "documents are represented by 9328 terms (stems). The dictionary (vocabulary) for the data set is given in the file\n",
    "\"terms.txt\" and the full term-by-document matrix is given in \"matrix.txt\" (comma separated values). The actual\n",
    "category labels for the documents are provided in the file \"classes.txt\". Your goal in this assignment is to perform\n",
    "clustering on the documents and compare the clusters to the actual categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "doc_classes = pd.read_csv(r'https://raw.githubusercontent.com/PixarJunkie/dsc478-programming-ml-applications/master/data/news-groups-data/classes.txt', sep = ' ', header = None, names = ['id', 'doc_class'])\n",
    "doc_classes.drop(columns = ['id'], inplace = True)\n",
    "doc_classes = doc_classes.doc_class.values\n",
    "term_matrix = np.loadtxt(r'https://raw.githubusercontent.com/PixarJunkie/dsc478-programming-ml-applications/master/data/news-groups-data/matrix.txt', delimiter = ',')\n",
    "terms = pd.read_csv(r'https://raw.githubusercontent.com/PixarJunkie/dsc478-programming-ml-applications/master/data/news-groups-data/terms.txt', sep = ' ', header = None, names = ['term'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2a \n",
    "Create your own distance function that, instead of using Euclidean distance, uses Cosine similarity.\n",
    "This is the distance function you will use to pass to the kMeans function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine similarity\n",
    "def cos_sim(x, y):\n",
    "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2b \n",
    "Load the data set Note: the data matrix provided has terms as rows and documents as columns.\n",
    "Since you will be clustering documents, you'll need to take the transpose of this matrix so that your main\n",
    "data matrix is a document x term matrix. In Numpy, you may use the \".T\" operation to obtain the\n",
    "transpose. Then, split the data set (the document x term matrix) and set aside 20% for later use (see\n",
    "below). Use the 80% segment for clustering in the next part. The 20% portion must be a random subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms_train shape: (2000, 9328)\n",
      "terms_test shape: (500, 9328)\n",
      "label_train shape: (2000,)\n",
      "label_test shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "#Transpose term_matrix\n",
    "term_matrix_t = term_matrix.T\n",
    "\n",
    "#Train test split\n",
    "terms_train, terms_test, label_train, label_test = train_test_split(term_matrix_t, doc_classes, test_size = 0.20, random_state = 23)\n",
    "print('terms_train shape: ' + str(terms_train.shape))\n",
    "print('terms_test shape: ' + str(terms_test.shape))\n",
    "print('label_train shape: ' + str(label_train.shape))\n",
    "print('label_test shape: ' + str(label_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2c \n",
    "Perform Kmeans clustering on the training data. Write a function to display the top N terms in each\n",
    "cluster along with the cluster DF values for each term and the size of the cluster. The cluster DF value\n",
    "for a term t in a cluster C is the percentage of docs in cluster C in which term t appears (so, if a cluster\n",
    "has 500 documents, and term \"game\" appears in 100 of those 500 documents, then DF value of \"game\"\n",
    "in that cluster is 0.2 or 20%). Sort the terms for each cluster in decreasing order of the DF percentage.\n",
    "Here is an example of how this output might look like (here the top 10 terms for 3 of the 5 clusters\n",
    "are displayed in decreasing order of cluster DF values, but the mean frequnecy from the cluster centroid\n",
    "is also shown). Extra Credit: use your favorite third party tool, ideally with a Python based API, to\n",
    "create a word cloud for each cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randCent(dataSet, k):\n",
    "\tn = dataSet.shape[1]\n",
    "\tcentroids = np.zeros((k,n), dtype=float)\n",
    "\tfor j in range(n): #create random cluster centers\n",
    "\t\tminJ = min(dataSet[:,j])\n",
    "\t\trangeJ = float(max(dataSet[:,j]) - minJ)\n",
    "\t\tcentroids[:,j] = minJ + rangeJ * np.random.rand(k)\n",
    "\treturn centroids \n",
    "\n",
    "def kMeans(dataSet, k, distMeas=cos_sim, createCent=randCent):\n",
    "    m = dataSet.shape[0]\n",
    "    clusterAssment = np.zeros((m,2))#create mat to assign data points \n",
    "                                      #to a centroid, also holds SE of each point\n",
    "    centroids = createCent(dataSet, k)\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        for i in range(m):#for each data point assign it to the closest centroid\n",
    "            minDist = np.inf; minIndex = -1\n",
    "            for j in range(k):\n",
    "                distJI = distMeas(centroids[j,:],dataSet[i,:])\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI; minIndex = j\n",
    "            if clusterAssment[i,0] != minIndex: clusterChanged = True\n",
    "            clusterAssment[i,:] = minIndex,minDist**2\n",
    "        # print centroids\n",
    "        for cent in range(k):#recalculate centroids\n",
    "            ptsInClust = dataSet[np.nonzero(clusterAssment[:,0]==cent)[0]] #get all the point in this cluster - Note: this was incorrect in the original distribution.\n",
    "            if(len(ptsInClust)!=0):\n",
    "                centroids[cent,:] = np.mean(ptsInClust, axis=0) #assign centroid to mean - Note condition was added 10/28/2013\n",
    "    return centroids, clusterAssment\n",
    "\n",
    "def biKmeans(dataSet, k, distMeas=cos_sim):\n",
    "    m = dataSet.shape[0]\n",
    "    clusterAssment = mat(np.zeros((m,2)))\n",
    "    centroid0 = mean(dataSet, axis=0).tolist()[0]\n",
    "    centList =[centroid0] #create a list with one centroid\n",
    "    for j in range(m): #calc initial Error\n",
    "        clusterAssment[j,1] = distMeas(mat(centroid0), dataSet[j,:])**2\n",
    "    while (len(centList) < k):\n",
    "        lowestSSE = np.inf\n",
    "        for i in range(len(centList)):\n",
    "            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:,0].A==i)[0],:] #get the data points currently in cluster i\n",
    "            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas)\n",
    "            sseSplit = sum(splitClustAss[:,1])#compare the SSE to the currrent minimum\n",
    "            sseNotSplit = sum(clusterAssment[np.nonzero(clusterAssment[:,0].A!=i)[0],1])\n",
    "            print (\"sseSplit, and notSplit: \",sseSplit,sseNotSplit)\n",
    "            if (sseSplit + sseNotSplit) < lowestSSE:\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = centroidMat\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = sseSplit + sseNotSplit\n",
    "        bestClustAss[np.nonzero(bestClustAss[:,0] == 1)[0],0] = len(centList) #change 1 to 3,4, or whatever\n",
    "        bestClustAss[np.nonzero(bestClustAss[:,0] == 0)[0],0] = bestCentToSplit\n",
    "        print ('the bestCentToSplit is: ',bestCentToSplit)\n",
    "        print ('the len of bestClustAss is: ', len(bestClustAss))\n",
    "        centList[bestCentToSplit] = bestNewCents[0,:].tolist()[0]#replace a centroid with two best centroids \n",
    "        centList.append(bestNewCents[1,:].tolist()[0])\n",
    "        clusterAssment[np.nonzero(clusterAssment[:,0].A == bestCentToSplit)[0],:]= bestClustAss#reassign new clusters, and SSE\n",
    "    return mat(centList), clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I run the below cell it loops forever and never finishes. I went ahead and compelted the other probelms with the base Kmeans though it's not utilizing the cosine similarity as the distance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans model\n",
    "kMeans(terms_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create kmeans model and fit to training set\n",
    "k = 5\n",
    "km = KMeans(n_clusters = k)\n",
    "km_model = km.fit(terms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe from clusters\n",
    "cluster_df = pd.DataFrame(terms_train)\n",
    "cluster_df['cluster'] = km_model.labels_\n",
    "\n",
    "#Print size of each cluster\n",
    "for i in range(0, k):\n",
    "    print(len(cluster_df[cluster_df.cluster == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  frequency     term\n",
      "0   7895     2149.0  subject\n",
      "1   5795     1541.0       on\n",
      "2   9129     1266.0    write\n",
      "3   3345     1068.0      god\n",
      "4   3266      953.0      get\n",
      "   index  frequency term\n",
      "0    547    11146.0   ax\n",
      "1   4982      800.0  max\n",
      "2   6183       41.0   pl\n",
      "3    442       17.0  asq\n",
      "4   6534       11.0   qq\n",
      "   index  frequency term\n",
      "0    547     8395.0   ax\n",
      "1   4982      610.0  max\n",
      "2   6183      122.0   pl\n",
      "3   9062       67.0   wm\n",
      "4   3302       55.0  giz\n",
      "   index  frequency term\n",
      "0    547     7675.0   ax\n",
      "1   4982      559.0  max\n",
      "2   6183       58.0   pl\n",
      "3   3302       20.0  giz\n",
      "4    501       10.0   au\n",
      "   index  frequency term\n",
      "0    547     9629.0   ax\n",
      "1   4982      695.0  max\n",
      "2   6183      105.0   pl\n",
      "3   3302       46.0  giz\n",
      "4   6534       25.0   qq\n"
     ]
    }
   ],
   "source": [
    "#Get frequency and index\n",
    "top_5_0 = cluster_df[cluster_df.cluster == 0].sum().sort_values(ascending = False).head()\n",
    "top_5_1 = cluster_df[cluster_df.cluster == 1].sum().sort_values(ascending = False).head()\n",
    "top_5_2 = cluster_df[cluster_df.cluster == 2].sum().sort_values(ascending = False).head()\n",
    "top_5_3 = cluster_df[cluster_df.cluster == 3].sum().sort_values(ascending = False).head()\n",
    "top_5_4 = cluster_df[cluster_df.cluster == 4].sum().sort_values(ascending = False).head()\n",
    "\n",
    "#Create df for each cluster and join to terms df\n",
    "top_0_df = pd.DataFrame({'index': list(top_5_0.index), 'frequency': list(top_5_0)})\n",
    "top_1_df = pd.DataFrame({'index': list(top_5_1.index), 'frequency': list(top_5_1)})\n",
    "top_2_df = pd.DataFrame({'index': list(top_5_2.index), 'frequency': list(top_5_2)})\n",
    "top_3_df = pd.DataFrame({'index': list(top_5_3.index), 'frequency': list(top_5_3)})\n",
    "top_4_df = pd.DataFrame({'index': list(top_5_4.index), 'frequency': list(top_5_4)})\n",
    "\n",
    "#Create index column in terms df\n",
    "terms['index'] = terms.index\n",
    "\n",
    "#Merge dataframes\n",
    "top_0_df = pd.merge(top_0_df, terms)\n",
    "top_1_df = pd.merge(top_1_df, terms)\n",
    "top_2_df = pd.merge(top_2_df, terms)\n",
    "top_3_df = pd.merge(top_3_df, terms)\n",
    "top_4_df = pd.merge(top_4_df, terms)\n",
    "\n",
    "print(top_0_df)\n",
    "print(top_1_df)\n",
    "print(top_2_df)\n",
    "print(top_3_df)\n",
    "print(top_4_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2d \n",
    "Using the cluster assignments from Kmeans clustering, compare your 5 clusters to the 5 pre-assigned\n",
    "classes by computing the Completeness and Homogeneity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogeneity: 0.19490056025800703\n",
      "completeness: 0.002519824241950802\n"
     ]
    }
   ],
   "source": [
    "#Predict training\n",
    "train_preds = km_model.predict(terms_train)\n",
    "\n",
    "#Homogeneity and completeness values\n",
    "hcv = homogeneity_completeness_v_measure(train_preds, label_train)\n",
    "print('homogeneity: ' + str(hcv[0]))\n",
    "print('completeness: ' + str(hcv[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem 2e \n",
    "Finally, using your cluster assignments as class labels, categorize each of the documents in the 20%\n",
    "set-aside data into each of the appropriate cluster. Your categorization should be based on Cosine\n",
    "similarity between each test document and cluster centroids. For each test document show the predicted\n",
    "class label as well as Cosine similarity to the corresponding cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping this since the cosine similarity is a major part of it and I couldn't get the kmeans function working."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
