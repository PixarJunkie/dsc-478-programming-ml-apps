{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import linalg as la\n",
    "from numpy import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 \n",
    "For this problem you will use an image segmentation data set for clustering. You will experiment with\n",
    "using PCA as an approach to reduce dimensionality and noise in the data. You will compare the\n",
    "results of clustering the data with and without PCA using the provided image class assignments as the\n",
    "ground truth. The data set is divided into three files. The file \"segmentation_data.txt\" contains data\n",
    "about images with each line corresponding to one image. Each image is represented by 19 features\n",
    "(these are the columns in the data and correspond to the feature names in the file\n",
    "\"segmentation_names.txt\". The file \"segmentation_classes.txt\" contains the class labels (the type of\n",
    "image) and a numeric class label for each of the corresponding images in the data file. After clustering\n",
    "the image data, you will use the class labels to measure completeness and homogeneity of the\n",
    "generated clusters. The data set used in this problem is based on the Image Segmentation data set\n",
    "at the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impo|rt data\n",
    "features = np.loadtxt(r'https://raw.githubusercontent.com/PixarJunkie/dsc478-programming-ml-apps/master/data/image-data/segmentation_data.txt', delimiter = ',')\n",
    "classes = pd.read_csv(r'https://raw.githubusercontent.com/PixarJunkie/dsc478-programming-ml-apps/master/data/image-data/segmentation_classes.txt', sep = '\\t', header = None, names = ['term', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1a \n",
    "Load in the image data matrix (with rows as images and columns as features). Also load in the numeric\n",
    "class labels from the segmentation class file. Using your favorite method (e.g., sklearn's min-max scaler),\n",
    "perform min-max normalization on the data matrix so that each feature is scaled to 0,1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minmax normalization\n",
    "min_max = MinMaxScaler()\n",
    "norm_feats = min_max.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1b \n",
    "Next, Perform Kmeans clustering (for this problem, use the Kmeans implementation in scikit-learn) on the\n",
    "image data (since there are a total 7 pre-assigned image classes, you should use K = 7 in your clustering).\n",
    "Use Euclidean distance as your distance measure for the clustering. Print the cluster centroids (use some\n",
    "formatting so that they are visually understandable). Compare your 7 clusters to the 7 pre-assigned classes\n",
    "by computing the Completeness and Homogeneity values of the generated clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogeneity: 0.613187012485301\n",
      "completeness: 0.6115021163370862\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Kmeans\n",
    "\n",
    "#clusters\n",
    "k = 7\n",
    "#Model/fit\n",
    "km = KMeans(n_clusters = k)\n",
    "km_fit = km.fit(norm_feats)\n",
    "\n",
    "#Centroids\n",
    "centers = km_fit.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1])\n",
    "\n",
    "#Predictions\n",
    "preds = km_fit.predict(norm_feats)\n",
    "\n",
    "#Homogeneity and completeness values\n",
    "hcv = homogeneity_completeness_v_measure(preds, classes['class'])\n",
    "print('homogeneity: ' + str(hcv[0]))\n",
    "print('completeness: ' + str(hcv[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1c \n",
    "Perform PCA on the normalized image data matrix. You may use the linear algebra package in Numpy or\n",
    "the Decomposition module in scikit-learn (the latter is much more efficient). Analyze the principal\n",
    "components to determine the number, r, of PCs needed to capture at least 95% of variance in the data.\n",
    "Then use these rcomponents as features to transform the data into a reduced dimension space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance: 0.9600589227704959\n",
      "num features for explained variance: 7\n"
     ]
    }
   ],
   "source": [
    "#PCA\n",
    "pca = PCA()\n",
    "pca_fit = pca.fit(norm_feats)\n",
    "\n",
    "#Explained variance\n",
    "exp_var = pca.explained_variance_ratio_\n",
    "\n",
    "#Find r where var >= 0.95\n",
    "sum_ = 0\n",
    "n = 0\n",
    "for num in pca.explained_variance_ratio_:\n",
    "    sum_ += num\n",
    "    n += 1\n",
    "    if sum_ >= 0.95:\n",
    "        print('explained variance: ' + str(sum_))\n",
    "        print('num features for explained variance: ' + str(n))\n",
    "        break\n",
    "        \n",
    "#New PCA\n",
    "pca_ = PCA(n_components = n)\n",
    "pca__fit = pca_.fit(norm_feats)\n",
    "#Transform norm_feats\n",
    "pca__fit_trans = pca_.fit_transform(norm_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1d \n",
    "Perform Kmeans again, but this time on the lower dimensional transformed data. Then, compute the\n",
    "Completeness and Homogeneity values of the new clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "homogeneity: 0.6118121490278483\n",
      "completeness: 0.6101643468512763\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Kmeans with transformed features\n",
    "\n",
    "#clusters\n",
    "k = 7\n",
    "#Model/fit\n",
    "km = KMeans(n_clusters = k)\n",
    "km_fit = km.fit(pca__fit_trans)\n",
    "\n",
    "#Centroids\n",
    "centers = km_fit.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1])\n",
    "\n",
    "#Predictions\n",
    "preds = km_fit.predict(pca__fit_trans)\n",
    "\n",
    "#Homogeneity and completeness values\n",
    "hcv = homogeneity_completeness_v_measure(preds, classes['class'])\n",
    "print('')\n",
    "print('homogeneity: ' + str(hcv[0]))\n",
    "print('completeness: ' + str(hcv[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1e \n",
    "Discuss your observations based on the comparison of the two clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the homogeneity and completeness seem to be very similar between both clustering results. This suggests that the same clustering performance is acheivable with a lower dimensionality of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 \n",
    "For this problem you will use a modified version of the item-based recommender algorithm from Ch.\n",
    "14 of Machine Learning in Action and use it on joke ratings data based on Jester Online Joke\n",
    "Recommender System. The modified version of the code is provided in the\n",
    "module itemBasedRec.py. Most of the module will be used as is, but you will add some additional\n",
    "functionality.\n",
    "The data set contains two files. The file \"modified_jester_data.csv\" contains the ratings on 100 jokes\n",
    "by 1000 users (each row is a user profile). The ratings have been normalized to be between 1 and 21 \n",
    "(a 20-point scale), with 1 being the lowest rating. A zero indicated a missing rating. The file \"jokes.csv\"\n",
    "contains the joke ids mapped to the actual text of the jokes.\n",
    "Your tasks in this problem are the following (please also see comments for the function stubs in the\n",
    "provided module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2a \n",
    "Load in the joke ratings data and the joke text data into appropriate data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "jokes = load_jokes(r'https://raw.githubusercontent.com/PixarJunkie/dsc478-programming-ml-applications/master/data/jokes-data/jokes.csv')\n",
    "user_ratings = pd.read_csv(r'https://raw.githubusercontent.com/PixarJunkie/dsc478-programming-ml-applications/master/data/jokes-data/modified_jester_data.csv', header = None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2b \n",
    "Complete the definition for the function \"test\". This function iterates over all users and for each performs\n",
    "evaluation (by calling the provided \"cross_validate_user\" function), and returns the error information\n",
    "necessary to compute Mean Absolute Error (MAE). Use this function to perform evaluation (wiht 20% testratio for each user) comparing MAE results using standard item-based collaborative filtering (based on the\n",
    "rating prediction function \"standEst\") with results using the SVD-based version of the rating item-based CF\n",
    "(using \"svdEst\" as the prediction engine). Note: See comments provided in the module for hints on\n",
    "accomplishing these tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecludSim(inA,inB):\n",
    "    return 1.0 / (1.0 + la.norm(inA - inB))\n",
    "\n",
    "def pearsSim(inA,inB):\n",
    "    if len(inA) < 3 : \n",
    "        return 1.0\n",
    "    return 0.5 + 0.5 * corrcoef(inA, inB, rowvar = 0)[0][1]\n",
    "\n",
    "def cosSim(inA,inB):\n",
    "    num = float(inA.T * inB)\n",
    "    denom = la.norm(inA)*la.norm(inB)\n",
    "    return 0.5 + 0.5 * (num / denom)\n",
    "\n",
    "def standEst(dataMat, user, simMeas, item):\n",
    "    n = shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    for j in range(n):\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0: \n",
    "            continue\n",
    "        overLap = nonzero(logical_and(dataMat[:,item]>0, \\\n",
    "                                      dataMat[:,j]>0))[0]\n",
    "        if len(overLap) == 0: \n",
    "            similarity = 0\n",
    "        else: \n",
    "            similarity = simMeas(dataMat[overLap,item], \\\n",
    "                                   dataMat[overLap,j])\n",
    "        #print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: \n",
    "        return 0\n",
    "    else: \n",
    "        return ratSimTotal/simTotal\n",
    "    \n",
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    n = shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    data=mat(dataMat)\n",
    "    U,Sigma,VT = la.svd(data)\n",
    "    Sig4 = mat(eye(4)*Sigma[:4]) #arrange Sig4 into a diagonal matrix\n",
    "    xformedItems = data.T * U[:,:4] * Sig4.I  #create transformed items\n",
    "    for j in range(n):\n",
    "        userRating = data[user,j]\n",
    "        if userRating == 0 or j==item: \n",
    "            continue\n",
    "        similarity = simMeas(xformedItems[item,:].T,\\\n",
    "                             xformedItems[j,:].T)\n",
    "        #print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: \n",
    "        return 0\n",
    "    else: \n",
    "        return ratSimTotal/simTotal\n",
    "\n",
    "# This function is not needed for Assignment 4, but may be useful for experimentation\n",
    "def recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst):\n",
    "    unratedItems = nonzero(dataMat[user,:].A==0)[1] #find unrated items \n",
    "    if len(unratedItems) == 0: \n",
    "        return 'you rated everything'\n",
    "    itemScores = []\n",
    "    for item in unratedItems:\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]\n",
    "\n",
    "# This function performs evaluatoin on a single user based on the test_ratio\n",
    "# For example, with test_ratio = 0.2, a randomly selected 20 percent of rated \n",
    "# items by the user are withheld and the rest are used to estimate the withheld ratings\n",
    "\n",
    "def cross_validate_user(dataMat, user, test_ratio, estMethod=standEst, simMeas=pearsSim):\n",
    "\tnumber_of_items = dataMat.shape[1]\n",
    "\trated_items_by_user = np.array([i for i in range(number_of_items) if dataMat[user, i]>0])\n",
    "\ttest_size = int(test_ratio * len(rated_items_by_user))\n",
    "\ttest_indices = np.random.randint(0, len(rated_items_by_user), test_size)\n",
    "\twithheld_items = rated_items_by_user[test_indices]\n",
    "\toriginal_user_profile = np.copy(dataMat[user])\n",
    "\tdataMat[user, withheld_items] = 0 # So that the withheld test items is not used in the rating estimation below\n",
    "\terror_u = 0.0\n",
    "\tcount_u = len(withheld_items)\n",
    "\n",
    "\t# Compute absolute error for user u over all test items\n",
    "\tfor item in withheld_items:\n",
    "\t\t# Estimate rating on the withheld itemsure\n",
    "\t\testimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "\t\terror_u = error_u + abs(estimatedScore - original_user_profile[item])\t\n",
    "\t\n",
    "\t# Now restore ratings of the withheld items to the user profile\n",
    "\tfor item in withheld_items:\n",
    "\t\tdataMat[user, item] = original_user_profile[item]\n",
    "\t\t\n",
    "\t# Return sum of absolute errors and the count of test cases for this user\n",
    "\t# Note that these will have to be accumulated for each user to compute MAE\n",
    "\treturn error_u, count_u\n",
    "\t\n",
    "def test(dataMat, test_ratio, estMethod):\n",
    "    #Capture total error and total count\n",
    "    tot_err = 0\n",
    "    tot_count = 0\n",
    "    #Pass each user through cross_validate_user()\n",
    "    for user in range(1, dataMat.shape[1]): \n",
    "        data = cross_validate_user(dataMat, user, test_ratio, estMethod = estMethod)\n",
    "        #Add the user total_error and count \n",
    "        tot_err += data[0]\n",
    "        tot_count = data[1]\n",
    "    #Calculate MAE\n",
    "    MAE = tot_err / tot_count\n",
    "    # Write this function to iterate over all users and for each perform evaluation by calling\n",
    "\t# the above cross_validate_user function on each user. MAE will be the ratio of total error \n",
    "\t# across all test cases to the total number of test cases, for all users\n",
    "    \n",
    "    print ('Mean Absoloute Error for ' + str(estMethod) + ' : ' + str(MAE))\n",
    "\n",
    "# def print_most_similar_jokes(dataMat, jokes, queryJoke, k, metric=pearsSim):\n",
    "# \t# Write this function to find the k most similar jokes (based on user ratings) to a queryJoke\n",
    "# \t# The queryJoke is a joke id as given in the 'jokes.csv' file (an corresponding to the a column in dataMat)\n",
    "# \t# You must compare ratings for the queryJoke (the column in dataMat corresponding to the joke), to all\n",
    "# \t# other joke rating vectors and return the top k. Note that this is the same as performing KNN on the \n",
    "#     # columns of dataMat. The function must retrieve the text of the joke from 'jokes.csv' file and print both\n",
    "# \t# the queryJoke text as well as the text of the returned jokes.\n",
    "\n",
    "def load_jokes(file):\n",
    "\tjokes = genfromtxt(file, delimiter=',', dtype=str)\n",
    "\tjokes = np.array(jokes[:,1])\n",
    "\treturn jokes\n",
    "\n",
    "def get_joke_text(jokes, id):\n",
    "\treturn jokes[id]\n",
    "\n",
    "# dataMat = genfromtxt('modified_jester_data.csv',delimiter=',')\n",
    "\n",
    "# test(dataMat, 0.2, svdEst)\n",
    "# test(dataMat, 0.2, standEst)\n",
    "\n",
    "# jokes = load_jokes('jokes.csv')\n",
    "# print_most_similar_jokes(dataMat, jokes, 3, 5, pearsSim)\n",
    "\n",
    "# ''' See example output below:\n",
    "# |\n",
    "# Selected joke: \n",
    "\n",
    "# Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\n",
    "\n",
    "# Top 5 Recommended jokes are :\n",
    "\n",
    "# Q: What's the difference between a Lawyer and a Plumber? A: A Plumber works to unclog the system. \n",
    "# _______________\n",
    "# What do you call an American in the finals of the world cup? \"Hey Beer Man!\" \n",
    "# _______________\n",
    "# Q. What's 200 feet long and has 4 teeth? <P>A. The front row at a Willie Nelson Concert. \n",
    "# _______________\n",
    "# A country guy goes into a city bar that has a dress code and the maitred' demands he wear a tie. Discouraged the guy goes to his car to sulk when inspiration strikes: He's got jumper cables in the trunk! So he wrapsthem around his neck sort of like a string tie (a bulky string tie to be sure) and returns to the bar. The maitre d' is reluctant but says to the guy \"Okay you're a pretty resourceful fellow you can come in... but just don't start anything\"!   \n",
    "# _______________\n",
    "# What do you get when you run over a parakeet with a lawnmower? <P>Shredded tweet. \n",
    "# _______________\n",
    "\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function (just pasting it here for easier access)\n",
    "def test(dataMat, test_ratio, estMethod):\n",
    "    #Capture total error and total count\n",
    "    tot_err = 0\n",
    "    tot_count = 0\n",
    "    #Pass each user through cross_validate_user()\n",
    "    for user in range(1, dataMat.shape[1]): \n",
    "        data = cross_validate_user(dataMat, user, test_ratio, estMethod = estMethod)\n",
    "        #Add the user total_error and count \n",
    "        tot_err += data[0]\n",
    "        tot_count = data[1]\n",
    "    #Calculate MAE\n",
    "    MAE = tot_err / tot_count\n",
    "    # Write this function to iterate over all users and for each perform evaluation by calling\n",
    "\t# the above cross_validate_user function on each user. MAE will be the ratio of total error \n",
    "\t# across all test cases to the total number of test cases, for all users\n",
    "    \n",
    "    print ('Mean Absoloute Error for ' + str(estMethod) + ' : ' + str(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absoloute Error for <function standEst at 0x000001F549ED62F0> : 740.4862381264498\n",
      "Mean Absoloute Error for <function svdEst at 0x000001F549ED6400> : 737.4038920946356\n"
     ]
    }
   ],
   "source": [
    "standest_ = test(user_ratings, .20, estMethod = standEst)\n",
    "svdest_ = test(user_ratings, .20, estMethod = svdEst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3c \n",
    "Write a new function \"print_most_similar_jokes\" which takes the joke ratings data, a query joke id, a\n",
    "parameter k for the number of nearest neighbors, and a similarity metric function, and prints the text of the\n",
    "query joke as well as the texts of the top k most similar jokes based on user ratings. Note: For hints on\n",
    "how to accomplish this task, please see comments at the end of the provided module as well as comments\n",
    "for the provided stub function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transpose user_ratings\n",
    "user_ratings = user_ratings.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_similar_jokes(dataMat, jokes, queryJoke, k, metric=pearsSim):\n",
    "    \n",
    "    #encode jokes\n",
    "    le = LabelEncoder()\n",
    "    jokes_enc = le.fit_transform(jokes)\n",
    "    \n",
    "    #Kmeans model\n",
    "\n",
    "    #Model/fit\n",
    "    knn = KNeighborsClassifier()\n",
    "    #fit knn\n",
    "    knn.fit(dataMat, jokes_enc)\n",
    "    \n",
    "    #Find k neighbors\n",
    "    dist, ind = knn.kneighbors([dataMat[queryJoke]], n_neighbors = k + 1) \n",
    "    \n",
    "    #What would be a more efficient way to exclude the identity from the output set? I added 1 to k and removed is, but I would think there's something much better :P \n",
    "    ind = ind.tolist()\n",
    "    ind = [[x for x in y if x != queryJoke] for y in ind]\n",
    "    \n",
    "    most_sim = [jokes[i] for i in ind]\n",
    "    \n",
    "    for joke in most_sim:\n",
    "        print(joke)\n",
    "    \n",
    "#     return dist, ind, most_sim\n",
    "\n",
    "\t# Write this function to find the k most similar jokes (based on user ratings) to a queryJoke\n",
    "\t# The queryJoke is a joke id as given in the 'jokes.csv' file (an corresponding to the a column in dataMat)\n",
    "\t# You must compare ratings for the queryJoke (the column in dataMat corresponding to the joke), to all\n",
    "\t# other joke rating vectors and return the top k. Note that this is the same as performing KNN on the \n",
    "    # columns of dataMat. The function must retrieve the text of the joke from 'jokes.csv' file and print both\n",
    "\t# the queryJoke text as well as the text of the returned jokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A dog walks into Western Union and asks the clerk to send a telegram. He fills out a form on which he writes down the telegram he wishes to send: \"Bow wow wow Bow wow wow.\"The clerk says \"You can add another \\'Bow wow\\' for the same price.\"The dog responded \"Now wouldn\\'t that sound a little silly?\"'\n",
      " 'How many men does it take to screw in a light bulb? One...men will screw anything.'\n",
      " 'Q:  What did the blind person say when given some matzah?A:  Who the hell wrote this?'\n",
      " 'Q. Did you hear about the dyslexic devil worshipper? A. He sold his soul to Santa.'\n",
      " 'They asked the Japanese visitor if they have elections in his country.  \"Every Morning\" he answers.']\n"
     ]
    }
   ],
   "source": [
    "print_most_similar_jokes(user_ratings, jokes, 15, 5, metric = ecludSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer\\'s disease\". The man replies \"Well thank God I don\\'t have cancer!\"'\n",
      " 'Two kindergarten girls were talking outside: one said \"You won\\'t believe what I saw on the patio yesterday--a condom!\"The second girl asked \"What\\'s a patio?\"'\n",
      " 'Out in the backwoods of some midwestern state little Johnny arrives at school an hour late.Teacher: \"Why are you so late John? \"Johny : \"My big brother got shot in the ass.\"(the teacher corrects his speech)Teacher: \"Rectum.\"Johnny : \"Wrecked him!? Hell It damn near killed him!\"'\n",
      " 'Two cannibals are eating a clown one turns to other and says: \"Does this taste funny to you?'\n",
      " 'A woman has twins and gives them up for adoption.  One of them goes to a family in Egypt and is named \"Amal.\"  The other goes to a  family in Spain; they name him \"Juan.\"  Years later Juan sends a picture of himself to his mom.  Upon receiving the picture she tells her husband that she wishes she also had a picture of Amal.  Her husband responds \"But they are twins-if you\\'ve seen Juan you\\'ve seen   Amal.'\n",
      " 'They asked the Japanese visitor if they have elections in his country.  \"Every Morning\" he answers.'\n",
      " 'The Chukcha (Russian Eskimo) phones up the Russian Parliament Building.  A guard answers. Chukcha:  \"What is required to become Parliament member?\"Guard:  \"What are you an idiot?\"Chukcha:  \"Is it required?\"'\n",
      " \"Q. What's 200 feet long and has 4 teeth? A. The front row at a Willie Nelson Concert.\"\n",
      " \"Q: What is the Australian word for a boomerang that won't   come back? A: A stick\"\n",
      " 'A Jewish young man was seeing a psychiatrist for an eating and sleeping disorder. \"I am so obsessed with my mother... As soon as I go to sleep I start dreaming and everyone in my dream turns into my mother. I wake up in such a state all I can do is go downstairs and eat a piece of toast.\"The psychiatrist replies:\"What just one piece of toast for a big boy like you?\"']\n"
     ]
    }
   ],
   "source": [
    "print_most_similar_jokes(user_ratings, jokes, 1, 10, metric = cosSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If pro- is the opposite of con- then congress must be the opposite of progress.'\n",
      " 'A man recently completing a routine physical examination receives a phone call from his doctor.  The doctor says \"I have some good news and some bad news.\"  The man says \"OK give me the good news first.\"  The doctor says \"The good news is you have 24 hours to live.\"  The man replies \"Shit!  That\\'s the good news?  Then what\\'s the bad news?\"The doctor says \"The bad news is I forgot to call you yesterday.\"'\n",
      " 'Q: What is the difference between Mechanical Engineers and Civil Engineers? A: Mechanical Engineers build weapons Civil Engineers build targets.']\n"
     ]
    }
   ],
   "source": [
    "print_most_similar_jokes(user_ratings, jokes, 80, 3, metric = pearsSim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
